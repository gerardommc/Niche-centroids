---
title: "Characterising centroids of simulated species"
author: "Gerardo Martín"
date: "17/9/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

These analyses are a comparison of two approaches to characterise niche centroids: *envelopes* and *point process models*, and ho the niche centroid estimates from these two methods may be affected by the statistical distribution of the environmental layers used to estimate them. The excercise is based purely on simulated datasets, incuding the environmental conditions. 

## Simulating \lq\lq environmental\rq\rq\ layers

Environmental conditions were simulated using a multivariate normal distribution pseudo-random number generator where the shared variance among numbers depends on an exponential kernel (a special case of the Mattérn function). If $x_1, x_2$ are two data points, the covariance function for those points is:

$$
\mathrm{cov} \left( x_1, x_2 \right) = \sigma^2 \exp \left( - \lambda \cdot \bar{s_{x_1, x_2}} \right)
$$

where $\sigma^2$ is the variance of the entire layer being simulated, $\bar{s}_{x_1, x_2}$ is the linear euclidean distance between pairs of points $x_1, x_2$, and $\lambda$ is the decay rate of the expected variance between pixels. Large $\lambda$ values result in layers with little spatial autocorrelation, whereas small $\lambda$ values make for whichly autocorrelated surfaces.

Using this method I generated five sets of ten normally-distributed layers. Each of the five sets differred in the settings used to generate each layer. Each layers' mean, $\sigma$ and $\lambda$ were generated randomly. Two sets had relatively large means, variances and decay rates, and the remaining three sets had small means. The layers with small means were used to generate the variables with log-normal, beta and gamma distributions, using each of the log-normal layers as the shape/rate parameters of the latter distributions.

## Simulating species

For this first excercise I generated all the possible combinations of three layers from the final 100 layers, and then randomly sampled 1000 combinations to simulate the species based on four scenarios on the basis of the location of the centroid. Each centroid setting was:

1. Mode or highest probability interval of each environmental layer (Centre)
2. Randomly selected value within the range of each variable (Random)
3. Close to a variable's largest or smallest value by randomly selecting the the 5$^{th}$ or 95$^{th}$, percentile (Edge)
4. Out of the range of simulated values, but relatively close to either the maximum of minimum ($x_{max/min} +/-  |x_{max/ min} - x_{99\%/1\%} |$ respectively; Outer)


Once obtained the centroid environmental coordinates I calculated the covariance between variables to project into a single raster layer, the Mahalanobis distance to the simulated centroids. Each distance-to-centroid layer was transformed to a probability layer using an exponential transform:

$$
P = \exp(-r \cdot \mathrm{dist}) \\
r = \frac{10}{\max(\mathrm{dist}) - \min(\mathrm{rist})}
$$
Then I generated 500 random points with the `randomPoints` function of the **dismo** package, using the probability surface as sampling probability.

## Characterising centroids

I tried to retrieve the centroids of the simulated species occurrences using the **ntbox** package function `ellipsoidfit` and with point process models (PPMs). For PPMs I used two approaches, one fitting a *saturated* model, using the same model formula for all species:

$$
\log(\lambda) = \alpha + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \beta'_1 X_1^2 + \beta'_2 X_2^2 + \beta'_3 X_3^2
$$

where the $X$'s are the environmental layers used to simulate each species, $\alpha$ is the model intercept, and $\beta$'s are each layer effects. In this case $\lambda$ refers to point intensity, in contrast with the exponential covariance function.

And then another PPM by stepping the model formula to reduce the AIC (*stepped* models).

To extract the centroids from these models after estimating $\alpha$ and $\beta$'s I obtained the partial derivative of $\log \lambda$ with respect to each $X$:

$$
\frac{\partial \log(\lambda)}{\partial X_i} = \beta_i + 2 \cdot \beta'_i X_i
$$

And then solved for $\partial \log \lambda / \partial X_i = 0 = X^* _i$, which corresponds to the $X_i$ value where  point intensity is the highest:

$$
X^*_i =  - \frac{\beta_i}{2 \cdot \beta'_i}
$$

This approach works if and only if $\beta'_i < 0$, and if the final model formula of the *stepped* models kept all terms for $X_{1, 2, 3}$.

### Comparing results

First, with the centroids estimated from each approach (traditional and ppm), I measured the Mahalanobis distance to the real centroid used for simulating species. Then I compared the surfaces generated by projecting the distance to the estimated centroid from the traditional approach and the estimated point intensity from the PPM approach and estimated the correlation between the surfaces.

Then I measured how the distance from the estimated centroids to the real centroids affected the similarity between model-generated surfaces and the surface used to simulate the occurrence records.

This is still an incomplete analysis as I'm yet to incorporate the type of distributions used for generating each species.

# Results

Surfaces generated by PPMs tended to be more similar to the surface that generated the data:

```{r Reading data, echo = F}

library(ggplot2); library(data.table)

ppms <- rbindlist(lapply(list.files("Simulated-species", "PPMs", full.names = T), read.csv))
ellips <-  rbindlist(lapply(list.files("Simulated-species", "llipses", full.names = T), read.csv))
#mod.ellips <- read.csv("Simulated-species/Results-mod-ellipses.csv")
all.results <- rbind(ppms, ellips)
```

```{r Plot-general-results, echo= F, fig.height=3, fig.width=6, fig.align='center'}
ggplot(all.results) + geom_violin(aes(x = approach, y = Corr.surf)) +
      geom_boxplot(aes(x = approach, y = Corr.surf), alpha = 0.5) +
      labs(x = "Approach", y = "Correlation with generating surface") +
   facet_grid(~centr.conf) + 
   theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

```{r fig.height=3, fig.width=6}
ggplot(all.results) + geom_violin(aes(x = approach, y = log10(Dist.true.cent), fill = approach, colour = approach), alpha = 0.3) +
      geom_boxplot(aes(x = approach, y = log10(Dist.true.cent), fill = approach, colour = approach), alpha = 0.5) +
      labs(x = "Approach", y = "Distance to true centroid") +
   facet_grid(~ centr.conf) +
   theme(axis.text.x = element_text(angle = 60, hjust = 1), 
         legend.position = "none")
```


This is because the centroids characterised with PPMs tended to be closer to the real centroid than centroids characterised by ellipses:

```{r echo=F, fig.height=3, fig.width=6, warning=FALSE, message = F, fig.align='center'}
ggplot(all.results) + geom_point(aes(x = log10(Dist.true.cent), y = Corr.surf, colour = approach), alpha = 0.1) + 
      geom_smooth(aes(x = log10(Dist.true.cent), y = Corr.surf, colour = approach, fill = approach), alpha = 0.5) + 
      labs(x = "log-Distance to true centroid", y = "Correlation with surface", 
           colour = "Approach", fill = "Approach") + 
   facet_grid(~ centr.conf) +
   theme(legend.position = "bottom")
```

A big problem for PPMs however, is that outliers, on the basis of distance to real centroids, are a lot farther away from the real centroids than for ellipses, and this is probably due to the polynomial nature of the formulas (i. e. $\beta'_i > 0$ will throw away any possible estimation of the centroid). By visual inspection of the above plots one would be fooled to think that higher correlation with the generating surface is enough to conclude that the approximation to the real centroid is better, because PPMs are almost always more correlated with the generating surface. But as I mentioned above, when $\beta'_i > 0$, ellipses are a better guess than PPMs.

I calculated the fraction of cases in which PPMs *outperformed* ellipses based on the similarity (correlation) between the estimated suitability surface (ellipsoids) and point intensity (PPMs) with the generating surface and the distance to the real centroid. To do this I substracted the correlation coefficient and the distance to true centroids respectively. PPMs far outperfom ellipses in their capacity to generate a surface that resembles the surface that generated the data by ~20-35 x:

```{r Differences between approaches}
ppms.sat <- subset(ppms, approach == "PPM-sat")
ppms.step <- subset(ppms, approach == "PPM-step")

corr.dif.sat <- ppms.sat$Corr.surf - ellips$Corr.surf
dist.dif.sat <- ellips$Dist.true.cent - ppms.sat$Dist.true.cent

nas <- !is.na(ppms.step$Dist.true.cent)

corr.dif.step <- ppms.step$Corr.surf[nas] - ellips$Corr.surf[nas]
dist.dif.step <- ellips$Dist.true.cent[nas] - ppms.step$Dist.true.cent[nas]

p.cor.sat <- length(which(corr.dif.sat > 0))/length(corr.dif.sat)
p.dif.sat <- length(which(dist.dif.sat > 0))/length(dist.dif.sat)

p.cor.step <- length(which(corr.dif.step > 0))/length(corr.dif.step)
p.dif.step <- length(which(dist.dif.step > 0))/length(dist.dif.step)

p.cor.sat/(1 - p.cor.sat)
p.cor.step/(1 - p.cor.step)
```

Regarding distance from the real centroid, the difference only marginally favours PPMs with *saturated* model formulas.

```{r}
p.dif.sat/(1 - p.dif.sat)
```

And clearly favours *stepped* PPMs if able to find statistical evidence of environmental effects:

```{r}
p.dif.step/(1 - p.dif.step)
```

Although confusing, this is very good evidence in favour of ellipses, because stepped PPMs only means good statistical evidence of clear environmental effents. In addition imputation of centroids, even when there is little statistical evidence, will be a lot closer than estimates from PPMs (these are thrown off the chart if any of the $\beta_i^' > 0$).

As mentioned above I will explore in greater detail the patterns in these synthetic analyses, first by accounting for the distribution of the variables used in the generating surfaces, and then trying to improve PPM estimates by tweaking model formulas.

## Deriving a statistical measure that explains *performance*

```{r}
library(raster); library(foreach)
all.layers <- readRDS("Simulated-layers/All-simulated-layers.rds")

config <- lapply(paste0("Simulated-species/Sim-config-species-list", 
                  c("", "-EdgeCentroids",
                    "-OuterCentroids",
                    "-RandomCentroids"), ".rds"), readRDS)

spp.layers <- foreach(k = 1:ncol(config[[1]]$layers)) %do% {
      dropLayer(all.layers, i = c(which(! 1:nlayers(all.layers) %in% config[[1]]$layers[, k])))
   }

pres <- lapply(paste0("Simulated-species/Species-presences",
                      c(".rds",
                        "-EdgeCentroids.rds",
                        "-OuterCentroids.rds",
                        "-RandomCentroids.rds")), readRDS)
```

```{r "computing skewness with fisher's method"}
library(parallel); library(doParallel)
s <- seq(1, 10000, by = 10)

env.skew <- mclapply(spp.layers, function(x){
      df <- as.matrix(x)[s, ]
      res <- MVN::mvn(df, mvnTest = "hz", multivariatePlot = F)$multivariateNormality$HZ
      return(res)
   },
   mc.cores = getOption("mc.cores", 6L))
env.skew <- unlist(env.skew)

registerDoParallel(cores = 4)
pres.skew <- foreach(i = seq_along(pres)) %do%{
   foreach(j = seq_along(pres[[i]]), .combine = c) %dopar% {
      df <- extract(spp.layers[[i]], pres[[i]][[j]])
      res <- MVN::mvn(df, mvnTest = "hz", multivariatePlot = F)$multivariateNormality$HZ
      #ske <- sum(abs(res[2,]))
      return(res)  
   }
}
pres.skew <- unlist(pres.skew)
```

```{r}
ppms.sat$Skewness.env <- rep(env.skew, 4)
ppms.step$Skewness.env <- rep(env.skew, 4)
ellips$Skewness.env <-  rep(env.skew, 4)

ppms.sat$Skewness.pres <- pres.skew
ppms.step$Skewness.pres <- pres.skew
ellips$Skewness.pres <- pres.skew

dat.skew <- rbind(ppms.sat, ellips)
dat.skew$Skew.dif <- with(dat.skew, Skewness.pres - Skewness.env)
```

```{r}
ggplot(dat.skew) + geom_boxplot(aes(x = centr.conf, y = Skew.dif)) + 
   geom_violin(aes(x = centr.conf, y = Skew.dif), alpha = 0.3)
```


```{r}
ggplot(ppms.sat) + geom_boxplot(aes(x = centr.conf, y = (Skewness.pres), fill = centr.conf), alpha = 0.3) 
ggplot(ppms.sat) + geom_boxplot(aes(x = centr.conf, y = log10(Skewness.env), fill = centr.conf), alpha = 0.3)

library(reshape)

dat.skew.long <- melt(dat.skew, measure.vars = c("Skewness.env", "Skewness.pres"))
```

```{r}
ggplot(dat.skew.long) + geom_point(aes(x = (value), y = log10(Dist.true.cent), colour = approach), alpha = 0.01) +
   facet_grid(rows = vars(variable), cols = vars(centr.conf))
```

```{r}
ggplot(dat.skew) + geom_hex(aes(x = Skewness.env, y = log10(Dist.true.cent))) + 
   scale_fill_continuous(type = "viridis", trans = "log10") +
   geom_smooth(aes(x = Skewness.env, y = log10(Dist.true.cent), colour = "red")) +
   facet_grid(rows = vars(approach), cols = vars(centr.conf))
```


```{r}
ggplot(dat.skew) + geom_hex(aes(x = Skewness.env, y = Corr.surf)) + 
   geom_smooth(aes(x = Skewness.env, y = Corr.surf, colour = "red"), alpha = 0.3, level = 0.01) +
   facet_grid(rows = vars(approach), cols = vars(centr.conf))
```

```{r}
ggplot(dat.skew) + geom_point(aes(x = Skewness.pres, y = Corr.surf, colour = approach), alpha = 0.3) + 
   geom_smooth(aes(x = Skewness.pres, y = Corr.surf, colour = approach), alpha = 0.3, method = "lm") +
   facet_grid(~ centr.conf)

ggplot(dat.skew) + geom_point(aes(x = Skewness.pres, y = log10(Dist.true.cent), colour = approach), alpha = 0.3) + 
   facet_grid(~ centr.conf)
ggplot(dat.skew) + geom_point(aes(x = Skewness.env, y = log10(Dist.true.cent), colour = approach), alpha = 0.3) + 
   facet_grid(~ centr.conf)

```


## Exploring the best and worst cases

For these analyses I used the distance to the real centroid. On this basis it turns out that both methods worked best for exactly the same case:

```{r Which is best or worse}
ellip.best <- which.min(ellips$Dist.true.cent)
ppm.best <- which.min(ppms$Dist.true.cent)

ellip.worst <- which.max(ellips$Dist.true.cent)
ppm.worst <- which.max(ppms$Dist.true.cent)
```

```{r}
ellip.best
ppm.best
```

The best-performing ellipse model turns out to have been generated with normally distributed variables (symmetric):

```{r}
ellips[ellip.best,]
```
And the best ppm included only one non-normal variable: 

```{r}
ppms[ppm.best, ]
```

The columns with the distribution's names indicate the number of layers of that distribution used for generating the *species*.

And in the worst case, the *species* were

```{r}
ellip.worst
ppm.worst
```

And were generated with the distributions, for the case of ellipses:

```{r}
ellips[ellip.worst,]
```

and for ppms:

```{r}
ppms[ppm.worst, ]
```
To no surprise both worst cases were generated with potentially asymmetric distributions.

### Details of the models for the worst cases

```{r echo=F, message = F}
library(spatstat); library(ntbox)

ppm.best.mod <- readRDS(paste0("../Resultados/Analysis-centroids/Fitted-PPMs/PPM-",ppm.best,".rds"))
ppm.worst.mod <- readRDS(paste0("../Resultados/Analysis-centroids/Fitted-PPMs/PPM-",ppm.worst,".rds"))

ellip.best.mod <- readRDS(paste0("../Resultados/Analysis-centroids/Fitted-ellipses/Ellips-",ellip.best,".rds"))
ellip.worst.mod <- readRDS(paste0("../Resultados/Analysis-centroids/Fitted-mod-ellipses/Mod-ellips-",ellip.worst,".rds"))
```


#### PPMs

I'll explore first the coefficients of the model:

```{r}
coef(ppm.worst.mod)
```

And as it turns out the estimate for $\beta'_a > 0$, which explains why the estimate of the centroid is so far off the real value.

In contrast with this model which performed so poorly on the basis of the estimated centroid, the model that got closest to the real value, estimated negative coefficients for all $\beta'_i$'s:

```{r}
coef(ppm.best.mod)
```

Now by examining all the models, the distance to the true centroid tends to be much larger among the models which fitted at least one positive coefficient, although some of the models with negative coefficients only also struggled a fair bit (outliers):

```{r, echo = F}
all.ppms <- lapply(paste0("../Resultados/Analysis-centroids/Fitted-PPMs/PPM-", 1:1000,".rds"), readRDS)
neg.coefs <- sapply(all.ppms, function(x){(any(x$coef[5:7] > 0))})

ppms$pos.neg <- neg.coefs
```

```{r fig.height=3, fig.width=3, fig.align='center', echo=F}
ggplot(ppms) + geom_violin(aes(x = pos.neg, y = log10(Dist.true.cent))) +
   geom_boxplot(aes(x = pos.neg, y = log10(Dist.true.cent)), alpha = 0.5) + 
   labs(x = "Positive cofficients in model", y = "log10 distance to true centroid")
   
```

#### Ellipses

For the case of the ellipses there is no alternative than having a close look at the distribution of the specific variables used: *log-normal*, *beta* and *gamma*:

```{r, echo = F, message = F, warning = F}
library(raster)
config <- readRDS("Simulated-species/Sim-config-species-list.rds")
layers <- readRDS("Simulated-layers/All-simulated-layers.rds")
lay.sum <- read.csv("Simulated-layers/Layer-summaries.csv")
```

```{r fig.height=9, fig.width=6, echo = F, fig.align='center'}
lay.gen.worst <- dropLayer(layers, which(! 1:100 %in% config$combinations[,config$sample[ellip.worst]] ))
par(mfrow = c(3, 2))
for(i in 1:3){
      plot(lay.gen.worst[[i]], main = c("Normal", "Log-normal", "Gamma")[i])
      density(lay.gen.worst[[i]], xlab = "Value", ylab = "Frequency")
      abline(v = lay.sum$means[config$combinations[, config$sample[ellip.worst]][i]])
      abline(v = ellip.worst.mod[[1]]$center[i], col = "red")
}
```

The black vertical lines represent the true centroid values to be retrieved, and the red vertical lines are the retrieved values. The distance between lines is what drove the poorer performance of this model in comparison with the rest. And as can be seen in the plot of "distance vs correlation", greater distance from the true centroids results in estimating a surface which resembles less the surface used to generate the data, especially with ellipses.

```{r fig.height=8, fig.width=4, echo = F, fig.align='center'}
p.pres <- readRDS("Simulated-species/P-presence.rds")
occurs <- readRDS("Simulated-species/Species-presences.rds")

par(mfrow = c(3,1))
plot(p.pres[[ellip.worst]], main = "Generating surface")
plot(ellip.worst.mod[[2]]$suitRaster, main = "Distance to estimated centroid")
plot(ellip.worst.mod[[2]]$suitRaster[], p.pres[[ellip.worst]][],
     xlab = "DNC", ylab = "Gen surface")
```

Qualitatively the ellipses generate a similar spatial pattern, but estimated distances do not generally correspond with probability of occurrence
